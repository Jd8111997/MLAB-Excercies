{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install einops","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:18.742988Z","iopub.execute_input":"2023-08-23T18:29:18.744261Z","iopub.status.idle":"2023-08-23T18:29:35.376945Z","shell.execute_reply.started":"2023-08-23T18:29:18.744207Z","shell.execute_reply":"2023-08-23T18:29:35.374995Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.6.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nfrom einops import rearrange, repeat, reduce\nimport torch as t","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:35.380343Z","iopub.execute_input":"2023-08-23T18:29:35.380924Z","iopub.status.idle":"2023-08-23T18:29:39.058041Z","shell.execute_reply.started":"2023-08-23T18:29:35.380869Z","shell.execute_reply":"2023-08-23T18:29:39.056928Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def assert_all_equal(actual: t.Tensor, expected: t.Tensor) -> None:\n    assert actual.shape == expected.shape, f\"Shape mismatch, got: {actual.shape}\"\n    assert (actual == expected).all(), f\"Value mismatch, got: {actual}\"\n    print(\"Passed!\")\n\n\ndef assert_all_close(actual: t.Tensor, expected: t.Tensor, rtol=1e-05, atol=0.0001) -> None:\n    assert actual.shape == expected.shape, f\"Shape mismatch, got: {actual.shape}\"\n    assert t.allclose(actual, expected, rtol=rtol, atol=atol)\n    print(\"Passed!\")\n    \ndef rearrange_1() -> t.Tensor:\n    \n    \"\"\"Return the following tensor using only torch.arange and einops.rearrange:\"\"\"\n    return rearrange(t.arange(3, 9), \"(h w) -> h w\", h = 3, w = 2)\n\nexpected = t.tensor([[3, 4], [5, 6], [7, 8]])\nassert_all_equal(rearrange_1(), expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.059607Z","iopub.execute_input":"2023-08-23T18:29:39.060260Z","iopub.status.idle":"2023-08-23T18:29:39.158464Z","shell.execute_reply.started":"2023-08-23T18:29:39.060223Z","shell.execute_reply":"2023-08-23T18:29:39.157076Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def rearrange_2() -> t.Tensor:\n    \"\"\"Return the following tensor using only torch.arange and einops.rearrange:\n\n    [[1, 2, 3],\n     [4, 5, 6]]\n    \"\"\"\n    return rearrange(t.arange(1, 7), \"(h w) -> h w\", h = 2, w = 3)\n\nassert_all_equal(rearrange_2(), t.tensor([[1, 2, 3], [4, 5, 6]]))","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.161420Z","iopub.execute_input":"2023-08-23T18:29:39.161807Z","iopub.status.idle":"2023-08-23T18:29:39.171326Z","shell.execute_reply.started":"2023-08-23T18:29:39.161775Z","shell.execute_reply":"2023-08-23T18:29:39.169404Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def rearrange_3() -> t.Tensor:\n    \n    \"\"\"Return the following tensor using only torch.arange and einops.rearrange:\n\n    [[[1], [2], [3], [4], [5], [6]]]\n    \"\"\"\n    return rearrange(t.arange(1, 7), \"(h w c) -> h w c\", h = 1, w = 6, c = 1)\n\nassert_all_equal(rearrange_3(), t.tensor([[[1], [2], [3], [4], [5], [6]]]))","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.173854Z","iopub.execute_input":"2023-08-23T18:29:39.174611Z","iopub.status.idle":"2023-08-23T18:29:39.185874Z","shell.execute_reply.started":"2023-08-23T18:29:39.174564Z","shell.execute_reply":"2023-08-23T18:29:39.184416Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"x = t.arange(5)\ny = t.Tensor(x.shape)\ny2 = t.Tensor(tuple(x.shape))\ny3 = t.Tensor(list(x.shape))\nprint(y, y2, y3)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.187317Z","iopub.execute_input":"2023-08-23T18:29:39.187676Z","iopub.status.idle":"2023-08-23T18:29:39.252975Z","shell.execute_reply.started":"2023-08-23T18:29:39.187645Z","shell.execute_reply":"2023-08-23T18:29:39.251585Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"tensor([7.1760e+22, 7.2250e+28, 1.5766e-19, 2.0431e+20, 8.5495e+20]) tensor([5.]) tensor([5.])\n","output_type":"stream"}]},{"cell_type":"code","source":"x = t.Tensor([False, True])\nprint(x.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.254635Z","iopub.execute_input":"2023-08-23T18:29:39.255052Z","iopub.status.idle":"2023-08-23T18:29:39.260413Z","shell.execute_reply.started":"2023-08-23T18:29:39.255015Z","shell.execute_reply":"2023-08-23T18:29:39.259531Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"torch.float32\n","output_type":"stream"}]},{"cell_type":"code","source":"try:\n    print(t.tensor([1, 2, 3, 4]).mean())\nexcept Exception as e:\n    print(\"Exception raised: \", e)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.261794Z","iopub.execute_input":"2023-08-23T18:29:39.262147Z","iopub.status.idle":"2023-08-23T18:29:39.346684Z","shell.execute_reply.started":"2023-08-23T18:29:39.262114Z","shell.execute_reply":"2023-08-23T18:29:39.345236Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Exception raised:  mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n","output_type":"stream"}]},{"cell_type":"code","source":"def temperatures_average(temps: t.Tensor) -> t.Tensor:\n    \"\"\"Return the average temperature for each week.\n\n    temps: a 1D temperature containing temperatures for each day.\n    Length will be a multiple of 7 and the first 7 days are for the first week, second 7 days for the second week, etc.\n\n    You can do this with a single call to reduce.\n    \"\"\"\n    assert len(temps) % 7 == 0\n    return reduce(temps, '(h 7) -> h', 'mean')\n\ntemps = t.tensor([71, 72, 70, 75, 71, 72, 70, 68, 65, 60, 68, 60, 55, 59, 75, 80, 85, 80, 78, 72, 83], dtype=t.float32)\nexpected = t.tensor([71.5714, 62.1429, 79.0])\nassert_all_close(temperatures_average(temps), expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.348287Z","iopub.execute_input":"2023-08-23T18:29:39.348743Z","iopub.status.idle":"2023-08-23T18:29:39.365081Z","shell.execute_reply.started":"2023-08-23T18:29:39.348701Z","shell.execute_reply":"2023-08-23T18:29:39.363542Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef temperatures_differences(temps: t.Tensor) -> t.Tensor:\n    \"\"\"For each day, subtract the average for the week the day belongs to.\n\n    temps: as above\n    \"\"\"\n    assert len(temps) % 7 == 0\n    temps_mean = temperatures_average(temps)\n    temps_mean_repeated = repeat(temps_mean, 'h -> (h 7)')\n    return temps - temps_mean_repeated\n    \n    \n\n\nexpected = t.tensor(\n    [\n        -0.5714,\n        0.4286,\n        -1.5714,\n        3.4286,\n        -0.5714,\n        0.4286,\n        -1.5714,\n        5.8571,\n        2.8571,\n        -2.1429,\n        5.8571,\n        -2.1429,\n        -7.1429,\n        -3.1429,\n        -4.0,\n        1.0,\n        6.0,\n        1.0,\n        -1.0,\n        -7.0,\n        4.0,\n    ]\n)\nactual = temperatures_differences(temps)\nassert_all_close(actual, expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.370267Z","iopub.execute_input":"2023-08-23T18:29:39.370720Z","iopub.status.idle":"2023-08-23T18:29:39.389093Z","shell.execute_reply.started":"2023-08-23T18:29:39.370683Z","shell.execute_reply":"2023-08-23T18:29:39.387799Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef temperatures_normalized(temps: t.Tensor) -> t.Tensor:\n    \"\"\"For each day, subtract the weekly average and divide by the weekly standard deviation.\n\n    temps: as above\n\n    Pass torch.std to reduce.\n    \"\"\"\n    temp_diff = temperatures_differences(temps)\n    std_div = reduce(temps, '(h 7) -> h', t.std)\n    std_div_repeat = repeat(std_div, 'h -> (h 7)')\n    return temp_diff / std_div_repeat\n\n\nexpected = t.tensor(\n    [\n        -0.3326,\n        0.2494,\n        -0.9146,\n        1.9954,\n        -0.3326,\n        0.2494,\n        -0.9146,\n        1.1839,\n        0.5775,\n        -0.4331,\n        1.1839,\n        -0.4331,\n        -1.4438,\n        -0.6353,\n        -0.8944,\n        0.2236,\n        1.3416,\n        0.2236,\n        -0.2236,\n        -1.5652,\n        0.8944,\n    ]\n)\nactual = temperatures_normalized(temps)\nassert_all_close(actual, expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.390494Z","iopub.execute_input":"2023-08-23T18:29:39.390853Z","iopub.status.idle":"2023-08-23T18:29:39.405313Z","shell.execute_reply.started":"2023-08-23T18:29:39.390805Z","shell.execute_reply":"2023-08-23T18:29:39.403930Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef batched_dot_product_nd(a: t.Tensor, b: t.Tensor) -> t.Tensor:\n    \"\"\"Return the batched dot product of a and b, where the first dimension is the batch dimension.\n\n    That is, out[i] = dot(a[i], b[i]) for i in 0..len(a).\n    a and b can have any number of dimensions greater than 1.\n\n    a: shape (b, i_1, i_2, ..., i_n)\n    b: shape (b, i_1, i_2, ..., i_n)\n\n    Returns: shape (b, )\n\n    Use torch.einsum. You can use the ellipsis \"...\" in the einsum formula to represent an arbitrary number of dimensions.\n    \"\"\"\n    assert a.shape == b.shape\n    dot = t.einsum('b...,b... -> b', a, b)\n    return dot\n\n\nactual = batched_dot_product_nd(t.tensor([[1, 1, 0], [0, 0, 1]]), t.tensor([[1, 1, 0], [1, 1, 0]]))\nexpected = t.tensor([2, 0])\nassert_all_equal(actual, expected)\nactual2 = batched_dot_product_nd(t.arange(12).reshape((3, 2, 2)), t.arange(12).reshape((3, 2, 2)))\nexpected2 = t.tensor([14, 126, 366])\nassert_all_equal(actual2, expected2)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.406716Z","iopub.execute_input":"2023-08-23T18:29:39.407238Z","iopub.status.idle":"2023-08-23T18:29:39.430288Z","shell.execute_reply.started":"2023-08-23T18:29:39.407189Z","shell.execute_reply":"2023-08-23T18:29:39.429218Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Passed!\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def identity_matrix(n: int) -> t.Tensor:\n    \"\"\"Return the identity matrix of size nxn.\n\n    Don't use torch.eye or similar.\n\n    Hint: you can do it with arange, rearrange, and ==.\n    Bonus: find a different way to do it.\n    \"\"\"\n    assert n >= 0\n    return (rearrange(t.arange(n), 'i->i 1') == t.arange(n)).float()\n\n\nassert_all_equal(identity_matrix(3), t.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\nassert_all_equal(identity_matrix(0), t.zeros((0, 0)))","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.431986Z","iopub.execute_input":"2023-08-23T18:29:39.432337Z","iopub.status.idle":"2023-08-23T18:29:39.450132Z","shell.execute_reply.started":"2023-08-23T18:29:39.432306Z","shell.execute_reply":"2023-08-23T18:29:39.448859Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Passed!\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef sample_distribution(probs: t.Tensor, n: int) -> t.Tensor:\n    \"\"\"Return n random samples from probs, where probs is a normalized probability distribution.\n\n    probs: shape (k,) where probs[i] is the probability of event i occurring.\n    n: number of random samples\n\n    Return: shape (n,) where out[i] is an integer indicating which event was sampled.\n\n    Use torch.rand and torch.cumsum to do this without any explicit loops.\n\n    Note: if you think your solution is correct but the test is failing, try increasing the value of n.\n    \"\"\"\n    assert abs(probs.sum() - 1.0) < 0.001\n    assert (probs >= 0).all()\n    cum_dist = t.cumsum(probs, 0)\n    rand_indices = t.rand(n, 1)\n    sample_indices = (rand_indices > cum_dist).sum(dim=-1)\n    return sample_indices\n\n\nn = 10000000\nprobs = t.tensor([0.05, 0.1, 0.1, 0.2, 0.15, 0.4])\nfreqs = t.bincount(sample_distribution(probs, n)) / n\nassert_all_close(freqs, probs, rtol=0.001, atol=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:39.452294Z","iopub.execute_input":"2023-08-23T18:29:39.452768Z","iopub.status.idle":"2023-08-23T18:29:40.085291Z","shell.execute_reply.started":"2023-08-23T18:29:39.452731Z","shell.execute_reply":"2023-08-23T18:29:40.083788Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef classifier_accuracy(scores: t.Tensor, true_classes: t.Tensor) -> t.Tensor:\n    \"\"\"Return the fraction of inputs for which the maximum score corresponds to the true class for that input.\n\n    scores: shape (batch, n_classes). A higher score[b, i] means that the classifier thinks class i is more likely.\n    true_classes: shape (batch, ). true_classes[b] is an integer from [0...n_classes).\n\n    Use torch.argmax.\n    \"\"\"\n    assert true_classes.max() < scores.shape[1]\n    return (t.argmax(scores, dim = -1) == true_classes).sum() / scores.shape[0]\n\n\nscores = t.tensor([[0.75, 0.5, 0.25], [0.1, 0.5, 0.4], [0.1, 0.7, 0.2]])\ntrue_classes = t.tensor([0, 1, 0])\nexpected = 2.0 / 3.0\nassert classifier_accuracy(scores, true_classes) == expected","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:40.088015Z","iopub.execute_input":"2023-08-23T18:29:40.089108Z","iopub.status.idle":"2023-08-23T18:29:40.098384Z","shell.execute_reply.started":"2023-08-23T18:29:40.089057Z","shell.execute_reply":"2023-08-23T18:29:40.097108Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# %%\ndef total_price_indexing(prices: t.Tensor, items: t.Tensor) -> float:\n    \"\"\"Given prices for each kind of item and a tensor of items purchased, return the total price.\n\n    prices: shape (k, ). prices[i] is the price of the ith item.\n    items: shape (n, ). A 1D tensor where each value is an item index from [0..k).\n\n    Use integer array indexing. The below document describes this for NumPy but it's the same in PyTorch:\n\n    https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n    \"\"\"\n    assert items.max() < prices.shape[0]\n    return prices[items].sum().item()\n\n\nprices = t.tensor([0.5, 1, 1.5, 2, 2.5])\nitems = t.tensor([0, 0, 1, 1, 4, 3, 2])\nassert total_price_indexing(prices, items) == 9.0","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:40.100318Z","iopub.execute_input":"2023-08-23T18:29:40.101084Z","iopub.status.idle":"2023-08-23T18:29:40.124386Z","shell.execute_reply.started":"2023-08-23T18:29:40.101035Z","shell.execute_reply":"2023-08-23T18:29:40.122932Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def gather_2d(matrix: t.Tensor, indexes: t.Tensor) -> t.Tensor:\n    \"\"\"Perform a gather operation along the second dimension.\n\n    matrix: shape (m, n)\n    indexes: shape (m, k)\n\n    Return: shape (m, k). out[i][j] = matrix[i][indexes[i][j]]\n\n    For this problem, the test already passes and it's your job to write at least three asserts relating the arguments and the output. This is a tricky function and worth spending some time to wrap your head around its behavior.\n\n    See: https://pytorch.org/docs/stable/generated/torch.gather.html?highlight=gather#torch.gather\n    \"\"\"\n    \n    assert indexes.shape[0] <= matrix.shape[0]\n    assert matrix.ndim == indexes.ndim\n    out = matrix.gather(1, indexes)\n    assert out.shape == indexes.shape\n    return out\n\n\nmatrix = t.arange(15).view(3, 5)\nindexes = t.tensor([[4], [3], [2]])\nexpected = t.tensor([[4], [8], [12]])\nassert_all_equal(gather_2d(matrix, indexes), expected)\nindexes2 = t.tensor([[2, 4], [1, 3], [0, 2]])\nexpected2 = t.tensor([[2, 4], [6, 8], [10, 12]])\nassert_all_equal(gather_2d(matrix, indexes2), expected2)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:40.126854Z","iopub.execute_input":"2023-08-23T18:29:40.127885Z","iopub.status.idle":"2023-08-23T18:29:40.144105Z","shell.execute_reply.started":"2023-08-23T18:29:40.127843Z","shell.execute_reply":"2023-08-23T18:29:40.142874Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Passed!\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def total_price_gather(prices: t.Tensor, items: t.Tensor) -> float:\n    \"\"\"Compute the same as total_price_indexing, but use torch.gather.\"\"\"\n    assert items.max() < prices.shape[0]\n    return prices.gather(0, items).sum().item()\n\n\nprices = t.tensor([0.5, 1, 1.5, 2, 2.5])\nitems = t.tensor([0, 0, 1, 1, 4, 3, 2])\nassert total_price_gather(prices, items) == 9.0","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:29:40.145753Z","iopub.execute_input":"2023-08-23T18:29:40.147449Z","iopub.status.idle":"2023-08-23T18:29:40.158496Z","shell.execute_reply.started":"2023-08-23T18:29:40.147411Z","shell.execute_reply":"2023-08-23T18:29:40.157441Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def integer_array_indexing(matrix: t.Tensor, coords: t.Tensor) -> t.Tensor:\n    \"\"\"Return the values at each coordinate using integer array indexing.\n\n    For details on integer array indexing, see:\n    https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n\n    matrix: shape (d_0, d_1, ..., d_n)\n    coords: shape (batch, n)\n\n    Return: (batch, )\n    \"\"\"\n    return matrix[tuple(coords.T)]\n\n\nmat_2d = t.arange(15).view(3, 5)\ncoords_2d = t.tensor([[0, 1], [0, 4], [1, 4]])\nactual = integer_array_indexing(mat_2d, coords_2d)\nassert_all_equal(actual, t.tensor([1, 4, 9]))\nmat_3d = t.arange(2 * 3 * 4).view((2, 3, 4))\ncoords_3d = t.tensor([[0, 0, 0], [0, 1, 1], [0, 2, 2], [1, 0, 3], [1, 2, 0]])\nactual = integer_array_indexing(mat_3d, coords_3d)\nassert_all_equal(actual, t.tensor([0, 5, 10, 15, 20]))","metadata":{"execution":{"iopub.status.busy":"2023-08-23T18:43:43.457054Z","iopub.execute_input":"2023-08-23T18:43:43.457490Z","iopub.status.idle":"2023-08-23T18:43:43.471448Z","shell.execute_reply.started":"2023-08-23T18:43:43.457456Z","shell.execute_reply":"2023-08-23T18:43:43.470085Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Passed!\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef batched_logsumexp(matrix: t.Tensor) -> t.Tensor:\n    \"\"\"For each row of the matrix, compute log(sum(exp(row))) in a numerically stable way.\n\n    matrix: shape (batch, n)\n\n    Return: (batch, ). For each i, out[i] = log(sum(exp(matrix[i]))).\n\n    Do this without using PyTorch's logsumexp function.\n\n    A couple useful blogs about this function:\n    - https://leimao.github.io/blog/LogSumExp/\n    - https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/\n    \"\"\"\n    \n    max_row = matrix.max(axis = -1).values.unsqueeze(1)\n    return max_row.squeeze() + t.log(t.exp(matrix - max_row).sum(axis = 1))\n    \n\n\nmatrix = t.tensor([[-1000, -1000, -1000, -1000], [1000, 1000, 1000, 1000]])\nexpected = t.tensor([-1000 + math.log(4), 1000 + math.log(4)])\nactual = batched_logsumexp(matrix)\nassert_all_close(actual, expected)\nmatrix2 = t.randn((10, 20))\nexpected2 = t.logsumexp(matrix2, dim=-1)\nactual2 = batched_logsumexp(matrix2)\nassert_all_close(actual2, expected2)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T19:07:01.950390Z","iopub.execute_input":"2023-08-23T19:07:01.951033Z","iopub.status.idle":"2023-08-23T19:07:01.968544Z","shell.execute_reply.started":"2023-08-23T19:07:01.950985Z","shell.execute_reply":"2023-08-23T19:07:01.966922Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Passed!\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef batched_softmax(matrix: t.Tensor) -> t.Tensor:\n    \"\"\"For each row of the matrix, compute softmax(row).\n\n    Do this without using PyTorch's softmax function.\n    Instead, use the definition of softmax: https://en.wikipedia.org/wiki/Softmax_function\n\n    matrix: shape (batch, n)\n\n    Return: (batch, n). For each i, out[i] should sum to 1.\n    \"\"\"\n    nominator = t.exp(matrix)\n    denom = nominator.sum(axis = 1)\n    return nominator / denom.unsqueeze(1)\n\n\nmatrix = t.arange(1, 6).view((1, 5)).float().log()\nexpected = t.arange(1, 6).view((1, 5)) / 15.0\nactual = batched_softmax(matrix)\nassert_all_close(actual, expected)\nfor i in [0.12, 3.4, -5, 6.7]:\n    assert_all_close(actual, batched_softmax(matrix + i))\nmatrix2 = t.rand((10, 20))\nactual2 = batched_softmax(matrix2)\nassert actual2.min() >= 0.0\nassert actual2.max() <= 1.0\nassert_all_equal(actual2.argsort(), matrix2.argsort())\nassert_all_close(actual2.sum(dim=-1), t.ones(matrix2.shape[:-1]))","metadata":{"execution":{"iopub.status.busy":"2023-08-23T19:23:25.397806Z","iopub.execute_input":"2023-08-23T19:23:25.398282Z","iopub.status.idle":"2023-08-23T19:23:25.421660Z","shell.execute_reply.started":"2023-08-23T19:23:25.398249Z","shell.execute_reply":"2023-08-23T19:23:25.419685Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Passed!\nPassed!\nPassed!\nPassed!\nPassed!\nPassed!\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def batched_logsoftmax(matrix: t.Tensor) -> t.Tensor:\n    \"\"\"Compute log(softmax(row)) for each row of the matrix.\n\n    matrix: shape (batch, n)\n\n    Return: (batch, n). For each i, exp(out[i]) should sum to 1.\n\n    Do this without using PyTorch's logsoftmax function.\n    For each row, subtract the maximum first to avoid overflow if the row contains large values.\n    \"\"\"\n    \n    max_row = matrix.max(axis = -1).values\n    return matrix - max_row - t.log(t.exp(matrix - max_row).sum(axis = 1, keepdim = True))\n\n\nmatrix = t.arange(1, 6).view((1, 5)).float()\nstart = 1000\nmatrix2 = t.arange(start + 1, start + 6).view((1, 5)).float()\nactual = batched_logsoftmax(matrix2)\nexpected = t.tensor([[-4.4519, -3.4519, -2.4519, -1.4519, -0.4519]])\nassert_all_close(actual, expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T19:51:56.836380Z","iopub.execute_input":"2023-08-23T19:51:56.836849Z","iopub.status.idle":"2023-08-23T19:51:56.850829Z","shell.execute_reply.started":"2023-08-23T19:51:56.836800Z","shell.execute_reply":"2023-08-23T19:51:56.849197Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef batched_cross_entropy_loss(logits: t.Tensor, true_labels: t.Tensor) -> t.Tensor:\n    \"\"\"Compute the cross entropy loss for each example in the batch.\n\n    logits: shape (batch, classes). logits[i][j] is the unnormalized prediction for example i and class j.\n    true_labels: shape (batch, ). true_labels[i] is an integer index representing the true class for example i.\n\n    Return: shape (batch, ). out[i] is the loss for example i.\n\n    Hint: convert the logits to log-probabilities using your batched_logsoftmax from above.\n    Then the loss for an example is just the negative of the log-probability that the model assigned to the true class. Use torch.gather to perform the indexing.\n    \"\"\"\n    \n    logprobs = batched_logsoftmax(logits)\n    gather_probs = logprobs.gather(1, true_labels.unsqueeze(1))\n    return -1 * gather_probs.squeeze()\n\n\nlogits = t.tensor([[float(\"-inf\"), float(\"-inf\"), 0], [1 / 3, 1 / 3, 1 / 3], [float(\"-inf\"), 0, 0]])\ntrue_labels = t.tensor([2, 0, 0])\nexpected = t.tensor([0.0, math.log(3), float(\"inf\")])\nactual = batched_cross_entropy_loss(logits, true_labels)\n#assert_all_close(actual, expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T19:51:58.435727Z","iopub.execute_input":"2023-08-23T19:51:58.436548Z","iopub.status.idle":"2023-08-23T19:51:58.445964Z","shell.execute_reply.started":"2023-08-23T19:51:58.436509Z","shell.execute_reply":"2023-08-23T19:51:58.444989Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"\ndef collect_rows(matrix: t.Tensor, row_indexes: t.Tensor) -> t.Tensor:\n    \"\"\"Return a 2D matrix whose rows are taken from the input matrix in order according to row_indexes.\n\n    matrix: shape (m, n)\n    row_indexes: shape (k,). Each value is an integer in [0..m).\n\n    Return: shape (k, n). out[i] is matrix[row_indexes[i]].\n    \"\"\"\n    assert row_indexes.max() < matrix.shape[0]\n    return matrix[row_indexes, ]\n\n\nmatrix = t.arange(15).view((5, 3))\nrow_indexes = t.tensor([0, 2, 1, 0])\nactual = collect_rows(matrix, row_indexes)\nexpected = t.tensor([[0, 1, 2], [6, 7, 8], [3, 4, 5], [0, 1, 2]])\nassert_all_equal(actual, expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T19:53:43.965020Z","iopub.execute_input":"2023-08-23T19:53:43.965597Z","iopub.status.idle":"2023-08-23T19:53:43.978562Z","shell.execute_reply.started":"2023-08-23T19:53:43.965557Z","shell.execute_reply":"2023-08-23T19:53:43.976972Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def collect_columns(matrix: t.Tensor, column_indexes: t.Tensor) -> t.Tensor:\n    \"\"\"Return a 2D matrix whose columns are taken from the input matrix in order according to column_indexes.\n\n    matrix: shape (m, n)\n    column_indexes: shape (k,). Each value is an integer in [0..n).\n\n    Return: shape (m, k). out[:, i] is matrix[:, column_indexes[i]].\n    \"\"\"\n    assert column_indexes.max() < matrix.shape[1]\n    return matrix[:, column_indexes]\n\n\nmatrix = t.arange(15).view((5, 3))\ncolumn_indexes = t.tensor([0, 2, 1, 0])\nactual = collect_columns(matrix, column_indexes)\nexpected = t.tensor([[0, 2, 1, 0], [3, 5, 4, 3], [6, 8, 7, 6], [9, 11, 10, 9], [12, 14, 13, 12]])\nassert_all_equal(actual, expected)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T19:54:51.518935Z","iopub.execute_input":"2023-08-23T19:54:51.519441Z","iopub.status.idle":"2023-08-23T19:54:51.533419Z","shell.execute_reply.started":"2023-08-23T19:54:51.519405Z","shell.execute_reply":"2023-08-23T19:54:51.532066Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"Passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import namedtuple\nTestCase = namedtuple(\"TestCase\", [\"output\", \"size\", \"stride\"])\ntest_input_a = t.tensor([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]])\ntest_cases = [\n    TestCase(output=t.tensor([0, 1, 2, 3]), size=(4,), stride=(1,)),\n    TestCase(output=t.tensor([[0, 1, 2], [5, 6, 7]]), size=(2, 3), stride=(5, 1)),\n    TestCase(output=t.tensor([[0, 0, 0], [11, 11, 11]]), size=(2, 3), stride=(11, 0)),\n    TestCase(output=t.tensor([0, 6, 12, 18]), size=(4,), stride=(6,)),\n    TestCase(output=t.tensor([[[0, 1, 2]], [[9, 10, 11]]]), size=(2, 1, 3), stride=(9, 0, 1)),\n    TestCase(\n        output=t.tensor([[[[0, 1], [2, 3]], [[4, 5], [6, 7]]], [[[12, 13], [14, 15]], [[16, 17], [18, 19]]]]),\n        size=(2, 2, 2, 2),\n        stride=(12, 4, 2, 1),\n    ),\n]\nfor (i, case) in enumerate(test_cases):\n    actual = test_input_a.as_strided(size=case.size, stride=case.stride)\n    if (case.output != actual).any():\n        print(f\"Test {i} failed:\")\n        print(f\"Expected: {case.output}\")\n        print(f\"Actual: {actual}\")\n    else:\n        print(f\"Test {i} passed!\")","metadata":{"execution":{"iopub.status.busy":"2023-08-23T20:17:16.396472Z","iopub.execute_input":"2023-08-23T20:17:16.397026Z","iopub.status.idle":"2023-08-23T20:17:16.420764Z","shell.execute_reply.started":"2023-08-23T20:17:16.396989Z","shell.execute_reply":"2023-08-23T20:17:16.418902Z"},"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"Test 0 passed!\nTest 1 passed!\nTest 2 passed!\nTest 3 passed!\nTest 4 passed!\nTest 5 passed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def test_relu(relu_func):\n    print(f\"Testing: {relu_func.__name__}\")\n    x = t.arange(-1, 3, dtype=t.float32, requires_grad=True)\n    out = relu_func(x)\n    expected = t.tensor([0.0, 0.0, 1.0, 2.0])\n    assert_all_close(out, expected)\n\n\ndef relu_clone_setitem(x: t.Tensor) -> t.Tensor:\n    \"\"\"Make a copy with torch.clone and then assign to parts of the copy.\"\"\"\n    zz = t.clone(x)\n    zz[zz < 0.0] = 0.0\n    return zz\n\n\ntest_relu(relu_clone_setitem)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T20:20:11.053232Z","iopub.execute_input":"2023-08-23T20:20:11.053685Z","iopub.status.idle":"2023-08-23T20:20:11.068462Z","shell.execute_reply.started":"2023-08-23T20:20:11.053649Z","shell.execute_reply":"2023-08-23T20:20:11.066386Z"},"trusted":true},"execution_count":163,"outputs":[{"name":"stdout","text":"Testing: relu_clone_setitem\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def relu_where(x: t.Tensor) -> t.Tensor:\n    \"\"\"Use torch.where.\"\"\"\n    return t.where(x < 0, t.tensor(0), x)\n\n\ntest_relu(relu_where)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T20:22:37.704506Z","iopub.execute_input":"2023-08-23T20:22:37.704993Z","iopub.status.idle":"2023-08-23T20:22:37.713947Z","shell.execute_reply.started":"2023-08-23T20:22:37.704956Z","shell.execute_reply":"2023-08-23T20:22:37.712526Z"},"trusted":true},"execution_count":170,"outputs":[{"name":"stdout","text":"Testing: relu_where\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def relu_maximum(x: t.Tensor) -> t.Tensor:\n    \"\"\"Use torch.maximum.\"\"\"\n    return t.maximum(t.tensor(0), x)\n\n\ntest_relu(relu_maximum)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T20:22:38.506596Z","iopub.execute_input":"2023-08-23T20:22:38.507133Z","iopub.status.idle":"2023-08-23T20:22:38.515644Z","shell.execute_reply.started":"2023-08-23T20:22:38.507093Z","shell.execute_reply":"2023-08-23T20:22:38.514564Z"},"trusted":true},"execution_count":171,"outputs":[{"name":"stdout","text":"Testing: relu_maximum\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def relu_abs(x: t.Tensor) -> t.Tensor:\n    \"\"\"Use torch.abs.\"\"\"\n    return (x.abs() + x) / 2.0\n\n\ntest_relu(relu_abs)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T20:23:37.475905Z","iopub.execute_input":"2023-08-23T20:23:37.476422Z","iopub.status.idle":"2023-08-23T20:23:37.485870Z","shell.execute_reply.started":"2023-08-23T20:23:37.476382Z","shell.execute_reply":"2023-08-23T20:23:37.484601Z"},"trusted":true},"execution_count":172,"outputs":[{"name":"stdout","text":"Testing: relu_abs\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"def relu_multiply_bool(x: t.Tensor) -> t.Tensor:\n    \"\"\"Create a boolean tensor and multiply the input by it elementwise.\"\"\"\n    return x * (x > 0)\n\n\ntest_relu(relu_multiply_bool)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T20:24:31.155850Z","iopub.execute_input":"2023-08-23T20:24:31.156369Z","iopub.status.idle":"2023-08-23T20:24:31.165524Z","shell.execute_reply.started":"2023-08-23T20:24:31.156331Z","shell.execute_reply":"2023-08-23T20:24:31.164234Z"},"trusted":true},"execution_count":173,"outputs":[{"name":"stdout","text":"Testing: relu_multiply_bool\nPassed!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}